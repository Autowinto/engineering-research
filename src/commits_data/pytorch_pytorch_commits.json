{
  "repo_name": "pytorch/pytorch",
  "commits": [
    {
      "sha": "1fcc4bc109c8110a1f2917cefd20e04a07ac6786",
      "message": "Don't look at TESTING_ONLY in fuzzer (#146870)\n\nLots of configs aren't meant to be set because they're testing only\n\nPull Request resolved: https://github.com/pytorch/pytorch/pull/146870\nApproved by: https://github.com/masnesral",
      "changes": [
        {
          "file": "torch/_inductor/fuzzer.py",
          "patch": "@@ -811,6 +811,7 @@ def bisect(self, num_attempts: int = 100, p: float = 0.5) -> list[ConfigType]:\n                 if (\n                     field_name not in config\n                     and not field_name.startswith(\"_\")\n+                    and \"TESTING_ONLY\" not in field_name\n                     and random.random() < p\n                 ):\n                     value = self.sample("
        }
      ]
    },
    {
      "sha": "8c45d44abba5e5da19fa84c03e1aa19f0cb09c7f",
      "message": "Skip distributed subprocess test internally as they don't work (#148909)\n\nFollow up from https://github.com/pytorch/pytorch/pull/146098\n\nPull Request resolved: https://github.com/pytorch/pytorch/pull/148909\nApproved by: https://github.com/janeyx99",
      "changes": [
        {
          "file": "test/distributed/test_c10d_common.py",
          "patch": "@@ -8,6 +8,7 @@\n import tempfile\n import threading\n import time\n+import unittest\n from contextlib import nullcontext\n from dataclasses import dataclass\n from datetime import timedelta\n@@ -35,6 +36,8 @@\n )\n from torch.testing._internal.common_utils import (\n     instantiate_parametrized_tests,\n+    IS_FBCODE,\n+    IS_SANDCASTLE,\n     load_tests,\n     parametrize,\n     retry_on_connect_failures,\n@@ -1908,6 +1911,7 @@ def test_init_process_group_for_all_backends(self):\n \n             dist.destroy_process_group()\n \n+    @unittest.skipIf(IS_FBCODE or IS_SANDCASTLE, \"subprocess test fails in fbcode\")\n     def test_default_process_group(self):\n         script = \"\"\"\n # Hide all GPUs"
        }
      ]
    },
    {
      "sha": "9fddbf34171e19085a5b2b0c8dbfde643fb290c7",
      "message": "Update the comment (#148726)\n\nDifferential Revision: D70747931\n\nPull Request resolved: https://github.com/pytorch/pytorch/pull/148726\nApproved by: https://github.com/yf225",
      "changes": [
        {
          "file": "torch/_inductor/config.py",
          "patch": "@@ -303,7 +303,6 @@ def prologue_fusion_enabled() -> bool:\n mixed_mm_choice: Literal[\"default\", \"triton\", \"aten\", \"heuristic\"] = \"heuristic\"\n \n # enable reordering pass for increasing overlap between compute and communication\n-# only use with fsdp\n reorder_for_compute_comm_overlap = False\n \n # passes (in execution order) for increasing overlap between compute and communication"
        }
      ]
    },
    {
      "sha": "295f2ed4d103017f7e19a7b8263ece606cd629db",
      "message": "Fix \"invalid application of 'sizeof' to an incomplete type\" (#148854)\n\nFixes with C++23 and constexpr std::unique_ptr\n\nPull Request resolved: https://github.com/pytorch/pytorch/pull/148854\nApproved by: https://github.com/Skylion007",
      "changes": [
        {
          "file": "torch/_export/serde/schema_check.py",
          "patch": "@@ -446,9 +446,9 @@ class ForwardRef {{\n \n  public:\n   ForwardRef(): ptr_(std::make_unique<T>()) {{}}\n-  ForwardRef(ForwardRef<T>&&) = default;\n+  ForwardRef(ForwardRef<T>&&);\n   ForwardRef(const ForwardRef<T>& other): ptr_(std::make_unique<T>(*other.ptr_)) {{}}\n-  ForwardRef<T>& operator=(ForwardRef<T>&&) = default;\n+  ForwardRef<T>& operator=(ForwardRef<T>&&);\n   ForwardRef<T>& operator=(const ForwardRef<T>& other) {{\n     ptr_ = std::make_unique<T>(*other.ptr_);\n     return *this;\n@@ -521,6 +521,9 @@ class F64 {{\n {\"\".join(cpp_enum_defs.values())}\n {\"\".join(dict(sorted(cpp_class_defs.items(), key=lambda x: class_ordering[x[0]])).values())}\n {chr(10).join(cpp_json_defs)}\n+\n+template <typename T> ForwardRef<T>::ForwardRef(ForwardRef<T>&&) = default;\n+template <typename T> ForwardRef<T>& ForwardRef<T>::operator=(ForwardRef<T>&&) = default;\n }} // namespace _export\n }} // namespace torch\n \"\"\""
        }
      ]
    },
    {
      "sha": "00cabd423544875a288e2f3488381c1196d5e4c0",
      "message": "[Inductor][Windows] add env_var switch to turn all Windows inductor UTs. (#148733)\n\nFor timeout reason, we can't turn on all Windows Inductor UTs in CI: https://github.com/pytorch/pytorch/issues/135927\nAnd without the UTs, we can't ensure Windows inductor quality.\n\nIntel team will do some local test for Windows inductor, but we still need to add a switch to turn on the full Windows inductor UTs.\n\nThe switch is an environment variable:\n```cmd\nset TORCHINDUCTOR_WINDOWS_TESTS=1\n```\nAfter setup this environment variable, we can turn on all Windows inductor UTs, It will not affect to PyTorch CI.\n\nPull Request resolved: https://github.com/pytorch/pytorch/pull/148733\nApproved by: https://github.com/jansel\n\nCo-authored-by: Jason Ansel <jansel@jansel.net>",
      "changes": [
        {
          "file": "torch/_dynamo/test_case.py",
          "patch": "@@ -11,6 +11,7 @@\n import contextlib\n import importlib\n import logging\n+import os\n from typing import Union\n \n import torch\n@@ -35,7 +36,11 @@ def run_tests(needs: Union[str, tuple[str, ...]] = ()) -> None:\n     if TEST_WITH_TORCHDYNAMO or TEST_WITH_CROSSREF:\n         return  # skip testing\n \n-    if not torch.xpu.is_available() and IS_WINDOWS:\n+    if (\n+        not torch.xpu.is_available()\n+        and IS_WINDOWS\n+        and os.environ.get(\"TORCHINDUCTOR_WINDOWS_TESTS\", \"0\") == \"0\"\n+    ):\n         return\n \n     if isinstance(needs, str):"
        }
      ]
    },
    {
      "sha": "31625b08b8a896de3118e54e1f97be12da90daad",
      "message": "Add ccode for FloorDiv (#148727)\n\nSummary: Add ccode for FloorDiv\n\nTest Plan: CIs\n\nDifferential Revision: D70749021\n\nPull Request resolved: https://github.com/pytorch/pytorch/pull/148727\nApproved by: https://github.com/bobrenjc93",
      "changes": [
        {
          "file": "torch/utils/_sympy/functions.py",
          "patch": "@@ -291,6 +291,11 @@ def eval(\n \n         return None\n \n+    def _ccode(self, printer):\n+        base = printer.parenthesize(self.base, PRECEDENCE[\"Atom\"] - 0.5)\n+        divisor = printer.parenthesize(self.divisor, PRECEDENCE[\"Atom\"] - 0.5)\n+        return f\"floor({base}/{divisor})\"\n+\n \n class ModularIndexing(sympy.Function):\n     \"\"\""
        }
      ]
    },
    {
      "sha": "2068235c0addeadddb699b62c294dbbd33e24d51",
      "message": "Add timm_efficientnet to flaky models after cuda 12.6 update in CI/CD (#148788)\n\nAfter https://github.com/pytorch/pytorch/pull/148612\nThis model have become flaky\n\nTracking this regression in an issue : https://github.com/pytorch/pytorch/issues/148699\n\nPull Request resolved: https://github.com/pytorch/pytorch/pull/148788\nApproved by: https://github.com/izaitsevfb, https://github.com/malfet",
      "changes": [
        {
          "file": "benchmarks/dynamo/check_accuracy.py",
          "patch": "@@ -12,6 +12,7 @@\n     \"yolov3\",\n     \"gluon_inception_v3\",\n     \"detectron2_maskrcnn_r_101_c4\",\n+    \"timm_efficientnet\",  # see https://github.com/pytorch/pytorch/issues/148699\n     \"XGLMForCausalLM\",  # discovered in https://github.com/pytorch/pytorch/pull/128148\n }\n "
        }
      ]
    },
    {
      "sha": "ea86b8d3154d6c5b612f19de671092b1ff70d6b9",
      "message": "Fix redistribution cost for all-reduce (#148761)\n\nThis issue seems to have been introduced in https://github.com/pytorch/pytorch/pull/119897. With the current implementation, it might be more favorable to perform a reduce_scatter followed by an all-gather than simply an all-reduce.\n\nThanks @lw for the helpful discussions on getting this PR out!\n\nPull Request resolved: https://github.com/pytorch/pytorch/pull/148761\nApproved by: https://github.com/Skylion007, https://github.com/lw, https://github.com/tianyu-l, https://github.com/fegin",
      "changes": [
        {
          "file": "torch/distributed/tensor/_collective_utils.py",
          "patch": "@@ -297,7 +297,7 @@ def allreduce_cost(bytes_gb: float, mesh_topo: MeshTopoInfo, mesh_dim: int) -> f\n     num_devices_on_mesh_dim = mesh_topo.mesh_dim_devices[mesh_dim]\n     mesh_dim_bandwidth = mesh_topo.mesh_dim_bandwidth[mesh_dim]\n     # allreduce have almost 2x comm bytes compare to allgather/reduce_scatter\n-    num_hops = 2 * num_devices_on_mesh_dim - 1\n+    num_hops = 2 * (num_devices_on_mesh_dim - 1)\n \n     latency = 6.6 + num_hops * mesh_topo.mesh_dim_latency[mesh_dim]\n     bw = (bytes_gb * num_hops / num_devices_on_mesh_dim) / mesh_dim_bandwidth"
        }
      ]
    }
  ]
}