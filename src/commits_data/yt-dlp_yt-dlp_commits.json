{
  "repo_name": "yt-dlp/yt-dlp",
  "commits": [
    {
      "sha": "bd0a66816934de70312eea1e71c59c13b401dc3a",
      "message": "[ie/pinterest] Fix extractor (#12538)\n\nCloses #12529\nAuthored by: mikf\n\nCo-authored-by: =?UTF-8?q?Mike=20F=C3=A4hrmann?= <mike_faehrmann@web.de>",
      "changes": [
        {
          "file": "yt_dlp/extractor/pinterest.py",
          "patch": "@@ -23,9 +23,9 @@ class PinterestBaseIE(InfoExtractor):\n     def _call_api(self, resource, video_id, options):\n         return self._download_json(\n             f'https://www.pinterest.com/resource/{resource}Resource/get/',\n-            video_id, f'Download {resource} JSON metadata', query={\n-                'data': json.dumps({'options': options}),\n-            })['resource_response']\n+            video_id, f'Download {resource} JSON metadata',\n+            query={'data': json.dumps({'options': options})},\n+            headers={'X-Pinterest-PWS-Handler': 'www/[username].js'})['resource_response']\n \n     def _extract_video(self, data, extract_formats=True):\n         video_id = data['id']"
        }
      ]
    },
    {
      "sha": "b8b47547049f5ebc3dd680fc7de70ed0ca9c0d70",
      "message": "[ie/twitter] Fix syndication token generation (#12537)\n\nFix 14cd7f3443c6da4d49edaefcc12da9dee86e243e\n\nAuthored by: bashonly",
      "changes": [
        {
          "file": "yt_dlp/extractor/twitter.py",
          "patch": "@@ -1334,7 +1334,7 @@ def _build_graphql_query(self, media_id):\n     def _generate_syndication_token(self, twid):\n         # ((Number(twid) / 1e15) * Math.PI).toString(36).replace(/(0+|\\.)/g, '')\n         translation = str.maketrans(dict.fromkeys('0.'))\n-        return js_number_to_string((int(twid) / 1e15) * math.PI, 36).translate(translation)\n+        return js_number_to_string((int(twid) / 1e15) * math.pi, 36).translate(translation)\n \n     def _call_syndication_api(self, twid):\n         self.report_warning("
        }
      ]
    },
    {
      "sha": "79ec2fdff75c8c1bb89b550266849ad4dec48dd3",
      "message": "[ie/youtube] Warn on missing formats due to SSAP (#12483)\n\nSee https://github.com/yt-dlp/yt-dlp/issues/12482\n\nAuthored by: coletdjnz",
      "changes": [
        {
          "file": "yt_dlp/extractor/youtube.py",
          "patch": "@@ -4266,6 +4266,7 @@ def build_fragments(f):\n             } for range_start in range(0, f['filesize'], CHUNK_SIZE))\n \n         for fmt in streaming_formats:\n+            client_name = fmt[STREAMING_DATA_CLIENT_NAME]\n             if fmt.get('targetDurationSec'):\n                 continue\n \n@@ -4310,6 +4311,12 @@ def build_fragments(f):\n                 fmt_url = url_or_none(try_get(sc, lambda x: x['url'][0]))\n                 encrypted_sig = try_get(sc, lambda x: x['s'][0])\n                 if not all((sc, fmt_url, player_url, encrypted_sig)):\n+                    self.report_warning(\n+                        f'Some {client_name} client formats have been skipped as they are missing a url. '\n+                        f'{\"Your account\" if self.is_authenticated else \"The current session\"} may have '\n+                        f'the SSAP (server-side ads) experiment which may be interfering with yt-dlp. '\n+                        f'Please see  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details.',\n+                        only_once=True)\n                     continue\n                 try:\n                     fmt_url += '&{}={}'.format(\n@@ -4356,7 +4363,6 @@ def build_fragments(f):\n                 self.report_warning(\n                     f'{video_id}: Some formats are possibly damaged. They will be deprioritized', only_once=True)\n \n-            client_name = fmt[STREAMING_DATA_CLIENT_NAME]\n             po_token = fmt.get(STREAMING_DATA_INITIAL_PO_TOKEN)\n \n             if po_token:"
        }
      ]
    },
    {
      "sha": "7508e34f203e97389f1d04db92140b13401dd724",
      "message": "[ie/niconico] Fix format sorting (#12442)\n\nAuthored by: xpadev-net",
      "changes": [
        {
          "file": "yt_dlp/extractor/niconico.py",
          "patch": "@@ -28,6 +28,7 @@\n     try_get,\n     unescapeHTML,\n     update_url_query,\n+    url_basename,\n     url_or_none,\n     urlencode_postdata,\n     urljoin,\n@@ -432,6 +433,7 @@ def _yield_dms_formats(self, api_data, video_id):\n                     'format_id': ('id', {str}),\n                     'abr': ('bitRate', {float_or_none(scale=1000)}),\n                     'asr': ('samplingRate', {int_or_none}),\n+                    'quality': ('qualityLevel', {int_or_none}),\n                 }), get_all=False),\n                 'acodec': 'aac',\n             }\n@@ -443,7 +445,9 @@ def _yield_dms_formats(self, api_data, video_id):\n         min_abr = min(traverse_obj(audios, (..., 'bitRate', {float_or_none})), default=0) / 1000\n         for video_fmt in video_fmts:\n             video_fmt['tbr'] -= min_abr\n-            video_fmt['format_id'] = f'video-{video_fmt[\"tbr\"]:.0f}'\n+            video_fmt['format_id'] = url_basename(video_fmt['url']).rpartition('.')[0]\n+            video_fmt['quality'] = traverse_obj(videos, (\n+                lambda _, v: v['id'] == video_fmt['format_id'], 'qualityLevel', {int_or_none}, any)) or -1\n             yield video_fmt\n \n     def _real_extract(self, url):"
        }
      ]
    },
    {
      "sha": "7126b472601814b7fd8c9de02069e8fff1764891",
      "message": "[ie/lbry] Raise appropriate error for non-media files (#12462)\n\nCloses #12182\nAuthored by: bashonly",
      "changes": [
        {
          "file": "yt_dlp/extractor/lbry.py",
          "patch": "@@ -26,6 +26,7 @@ class LBRYBaseIE(InfoExtractor):\n     _CLAIM_ID_REGEX = r'[0-9a-f]{1,40}'\n     _OPT_CLAIM_ID = f'[^$@:/?#&]+(?:[:#]{_CLAIM_ID_REGEX})?'\n     _SUPPORTED_STREAM_TYPES = ['video', 'audio']\n+    _UNSUPPORTED_STREAM_TYPES = ['binary']\n     _PAGE_SIZE = 50\n \n     def _call_api_proxy(self, method, display_id, params, resource):\n@@ -341,7 +342,7 @@ def _real_extract(self, url):\n                 HEADRequest(streaming_url), display_id, headers=headers,\n                 note='Downloading streaming redirect url info').url\n \n-        elif result.get('value_type') == 'stream':\n+        elif result.get('value_type') == 'stream' and stream_type not in self._UNSUPPORTED_STREAM_TYPES:\n             claim_id, is_live = result['signing_channel']['claim_id'], True\n             live_data = self._download_json(\n                 'https://api.odysee.live/livestream/is_live', claim_id,"
        }
      ]
    },
    {
      "sha": "a59abe0636dc49b22a67246afe35613571b86f05",
      "message": "[ie/instagram] Fix extraction of older private posts (#12451)\n\nAuthored by: bashonly",
      "changes": [
        {
          "file": "yt_dlp/extractor/instagram.py",
          "patch": "@@ -33,8 +33,10 @@ def _pk_to_id(media_id):\n \n \n def _id_to_pk(shortcode):\n-    \"\"\"Covert a shortcode to a numeric value\"\"\"\n-    return decode_base_n(shortcode[:11], table=_ENCODING_CHARS)\n+    \"\"\"Convert a shortcode to a numeric value\"\"\"\n+    if len(shortcode) > 28:\n+        shortcode = shortcode[:-28]\n+    return decode_base_n(shortcode, table=_ENCODING_CHARS)\n \n \n class InstagramBaseIE(InfoExtractor):"
        }
      ]
    },
    {
      "sha": "c2e6e1d5f77f3b720a6266f2869eb750d20e5dc1",
      "message": "[ie/niconico:live] Fix thumbnail extraction (#12419)\n\nCloses #12417\nAuthored by: bashonly",
      "changes": [
        {
          "file": "yt_dlp/extractor/niconico.py",
          "patch": "@@ -13,11 +13,13 @@\n     ExtractorError,\n     OnDemandPagedList,\n     clean_html,\n+    determine_ext,\n     float_or_none,\n     int_or_none,\n     join_nonempty,\n     parse_duration,\n     parse_iso8601,\n+    parse_qs,\n     parse_resolution,\n     qualities,\n     remove_start,\n@@ -1033,6 +1035,7 @@ def _real_extract(self, url):\n                 thumbnails.append({\n                     'id': f'{name}_{width}x{height}',\n                     'url': img_url,\n+                    'ext': traverse_obj(parse_qs(img_url), ('image', 0, {determine_ext(default_ext='jpg')})),\n                     **res,\n                 })\n "
        }
      ]
    },
    {
      "sha": "1295bbedd45fa8d9bc3f7a194864ae280297848e",
      "message": "[ie/francetv:site] Fix livestream extraction (#12316)\n\nCloses #12310\r\nAuthored by: bashonly",
      "changes": [
        {
          "file": "yt_dlp/extractor/francetv.py",
          "patch": "@@ -358,7 +358,8 @@ def _real_extract(self, url):\n             # For livestreams we need the id of the stream instead of the currently airing episode id\n             video_id = traverse_obj(nextjs_data, (\n                 ..., ..., 'children', ..., 'children', ..., 'children', ..., 'children', ..., ...,\n-                'children', ..., ..., 'children', ..., ..., 'children', ..., 'options', 'id', {str}, any))\n+                'children', ..., ..., 'children', ..., ..., 'children', (..., (..., ...)),\n+                'options', 'id', {str}, any))\n         else:\n             video_id = traverse_obj(nextjs_data, (\n                 ..., ..., ..., 'children',"
        }
      ]
    },
    {
      "sha": "d59f14a0a7a8b55e6bf468237def62b73ab4a517",
      "message": "[ie/goplay] Fix extractor (#12237)\n\nAuthored by: alard",
      "changes": [
        {
          "file": "yt_dlp/extractor/goplay.py",
          "patch": "@@ -12,7 +12,6 @@\n from ..utils import (\n     ExtractorError,\n     int_or_none,\n-    js_to_json,\n     remove_end,\n     traverse_obj,\n )\n@@ -76,6 +75,7 @@ def _real_initialize(self):\n         if not self._id_token:\n             raise self.raise_login_required(method='password')\n \n+    # XXX: For parsing next.js v15+ data; see also yt_dlp.extractor.francetv\n     def _find_json(self, s):\n         return self._search_json(\n             r'\\w+\\s*:\\s*', s, 'next js data', None, contains_pattern=r'\\[(?s:.+)\\]', default=None)\n@@ -86,9 +86,10 @@ def _real_extract(self, url):\n \n         nextjs_data = traverse_obj(\n             re.findall(r'<script[^>]*>\\s*self\\.__next_f\\.push\\(\\s*(\\[.+?\\])\\s*\\);?\\s*</script>', webpage),\n-            (..., {js_to_json}, {json.loads}, ..., {self._find_json}, ...))\n+            (..., {json.loads}, ..., {self._find_json}, ...))\n         meta = traverse_obj(nextjs_data, (\n-            ..., lambda _, v: v['meta']['path'] == urllib.parse.urlparse(url).path, 'meta', any))\n+            ..., ..., 'children', ..., ..., 'children',\n+            lambda _, v: v['video']['path'] == urllib.parse.urlparse(url).path, 'video', any))\n \n         video_id = meta['uuid']\n         info_dict = traverse_obj(meta, {"
        }
      ]
    }
  ]
}